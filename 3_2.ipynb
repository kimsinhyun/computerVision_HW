{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69a4b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from turtle import forward\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary   import summary\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2254bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_number(col):\n",
    "    return int(col.split(\".\")[0])\n",
    "\n",
    "class MyDataset(Dataset) :\n",
    "\n",
    "    def __init__(self,meta_path,root_dir,transform=None) :\n",
    "        super().__init__()\n",
    "        #===============meta data===============\n",
    "        with open(meta_path, 'r') as file:\n",
    "            temp_meta_data = json.load(file)\n",
    "        self.meta = pd.json_normalize(temp_meta_data['annotations'])\n",
    "        self.meta['file_name'] = self.meta['file_name'].apply(parse_file_number)\n",
    "        self.meta = self.meta.sort_values(\"file_name\").reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.meta)\n",
    "    \n",
    "    def __getitem__(self,idx) :\n",
    "        img_path = os.path.join(self.root_dir, str(idx)) + \".jpg\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        y_label = (int(self.meta.loc[idx, 'category']))\n",
    "#         if self.transform:\n",
    "        img = self.transform(img)\n",
    "        return (img, y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92eedde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train' \n",
    "train_data_dir = \"./train_data\"\n",
    "meta_path = \"./answer.json\"\n",
    "\n",
    "# Create training and validation datasets\n",
    "# test_datasets = MyDataset(meta_path, data_dir, data_transforms['train'])\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((600,600)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_data = MyDataset(meta_path, train_data_dir, transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f7b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tf = transforms.ToPILImage()\n",
    "\n",
    "# test_tf(train_data[11365][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454d5f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ed7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900722d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43938d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c116918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module) :\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        #TODO: Make your own model\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channles = out_channels\n",
    "        self.layer = nn.Sequential(\n",
    "            #batch = 1, channel 3, height 400, width = 600 \n",
    "            #Conv [1, 3, 600, 600] -> [1, 16, 598, 598]\n",
    "            nn.Conv2d(in_channels = 3,  out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "              \n",
    "            #Conv [1, 16, 598, 598] -> [1, 32, 596, 596]\n",
    "            nn.Conv2d(in_channels = 16,  out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #Pool [1, 32, 596, 596] -> [1, 32, 298, 298]\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #Conv [1, 32, 298, 298] -> [1, 64, 296, 296]\n",
    "            nn.Conv2d(in_channels = 32,  out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #Pool [1, 64, 296, 296] -> [1, 64, 148, 148] \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #Conv [1, 64, 148, 148] -> [1, 128, 146, 146]\n",
    "            nn.Conv2d(in_channels = 64,  out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #Conv [1, 128, 146, 146] -> [1, 256, 144, 144]\n",
    "            nn.Conv2d(in_channels = 128,  out_channels=256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #Pool [1, 256, 144, 144]-> [1, 256, 72, 72] \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #Conv [1, 256, 72, 72] -> [1, 512, 70, 70]\n",
    "            nn.Conv2d(in_channels = 256,  out_channels=512, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #Conv [1, 512, 70, 70] -> [1, 1024, 68, 68]\n",
    "            nn.Conv2d(in_channels = 512,  out_channels=1024, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #Pool [1, 1024, 68, 68] -> [1, 1024, 34, 34]\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            #linear [1, 512 * 36 * 36] -> [100, 100]\n",
    "            nn.Linear(1024*34*34, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,80)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x) :\n",
    "        #TODO:\n",
    "#         print(\"x.shape: \", x.shape)\n",
    "        out = self.layer(x)\n",
    "#         print(\"out.shape: \", out.shape)\n",
    "        out = out.view(1, -1)\n",
    "#         print(\"out.size(0): \", out.size(0))\n",
    "        out = self.fc_layer(out)\n",
    "        return out \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c592ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea062961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7c7503",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch = 1\n",
    "learning_rate = 0.001\n",
    "model  = MyModel(3,128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc9b25aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       448\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─Conv2d: 2-3                       4,640\n",
      "|    └─ReLU: 2-4                         --\n",
      "|    └─MaxPool2d: 2-5                    --\n",
      "|    └─Conv2d: 2-6                       18,496\n",
      "|    └─ReLU: 2-7                         --\n",
      "|    └─MaxPool2d: 2-8                    --\n",
      "|    └─Conv2d: 2-9                       73,856\n",
      "|    └─ReLU: 2-10                        --\n",
      "|    └─Conv2d: 2-11                      295,168\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─MaxPool2d: 2-13                   --\n",
      "|    └─Conv2d: 2-14                      1,180,160\n",
      "|    └─ReLU: 2-15                        --\n",
      "|    └─Conv2d: 2-16                      4,719,616\n",
      "|    └─ReLU: 2-17                        --\n",
      "|    └─MaxPool2d: 2-18                   --\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─Linear: 2-19                      1,183,745,000\n",
      "|    └─ReLU: 2-20                        --\n",
      "|    └─Linear: 2-21                      80,080\n",
      "=================================================================\n",
      "Total params: 1,190,117,464\n",
      "Trainable params: 1,190,117,464\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       448\n",
       "|    └─ReLU: 2-2                         --\n",
       "|    └─Conv2d: 2-3                       4,640\n",
       "|    └─ReLU: 2-4                         --\n",
       "|    └─MaxPool2d: 2-5                    --\n",
       "|    └─Conv2d: 2-6                       18,496\n",
       "|    └─ReLU: 2-7                         --\n",
       "|    └─MaxPool2d: 2-8                    --\n",
       "|    └─Conv2d: 2-9                       73,856\n",
       "|    └─ReLU: 2-10                        --\n",
       "|    └─Conv2d: 2-11                      295,168\n",
       "|    └─ReLU: 2-12                        --\n",
       "|    └─MaxPool2d: 2-13                   --\n",
       "|    └─Conv2d: 2-14                      1,180,160\n",
       "|    └─ReLU: 2-15                        --\n",
       "|    └─Conv2d: 2-16                      4,719,616\n",
       "|    └─ReLU: 2-17                        --\n",
       "|    └─MaxPool2d: 2-18                   --\n",
       "├─Sequential: 1-2                        --\n",
       "|    └─Linear: 2-19                      1,183,745,000\n",
       "|    └─ReLU: 2-20                        --\n",
       "|    └─Linear: 2-21                      80,080\n",
       "=================================================================\n",
       "Total params: 1,190,117,464\n",
       "Trainable params: 1,190,117,464\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(3,600,600),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde829e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc1c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca62d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,(img, label) in enumerate(train_loader):\n",
    "#     print(i)\n",
    "#     print(img)    \n",
    "#     print(label)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f350cc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x21034b94940>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c265a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_arr =[]\n",
    "# num_epoch = 1\n",
    "# for i in range(num_epoch):\n",
    "#     print(\"i: \", i)\n",
    "#     for j,(image,label) in (train_loader):\n",
    "#         print(\"1\")\n",
    "#         x = image.to(device)\n",
    "#         print(\"2\")\n",
    "#         y= label.to(device)\n",
    "#         print(\"3\")\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         output = model.forward(x)\n",
    "#         print(\"j: \", j)\n",
    "        \n",
    "#         loss = loss_func(output,y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if j % 1000 == 0:\n",
    "#             print(loss)\n",
    "#             loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "968a8941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 1/40000 [00:05<57:39:03,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3903, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 11/40000 [00:56<58:20:19,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3676, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 21/40000 [01:51<66:11:39,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3873, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 31/40000 [02:43<57:35:34,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3640, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 41/40000 [03:35<57:40:22,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3766, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 51/40000 [04:30<61:14:32,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4014, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 61/40000 [05:26<63:14:03,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3826, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                           | 71/40000 [06:18<58:58:24,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3306, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                           | 81/40000 [07:18<73:33:48,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3547, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                           | 91/40000 [08:09<56:24:44,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4159, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                          | 101/40000 [09:00<57:56:32,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3368, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                          | 111/40000 [09:50<55:59:19,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3462, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                          | 121/40000 [10:40<55:36:15,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3303, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                          | 131/40000 [11:35<59:48:40,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3529, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                          | 141/40000 [12:30<66:26:02,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3999, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                          | 151/40000 [13:21<57:59:53,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3347, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                          | 161/40000 [14:14<58:04:24,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3510, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                          | 171/40000 [15:05<56:30:25,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3196, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                          | 181/40000 [15:54<55:26:13,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5144, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                          | 191/40000 [16:45<55:15:03,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4146, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                          | 193/40000 [16:57<58:17:59,  5.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output,y)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m( j \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_arr =[]\n",
    "num_epoch = 1\n",
    "for i in range(num_epoch):\n",
    "    loop = tqdm(train_loader, total = len(train_loader), leave=True)\n",
    "    for j, (image, label) in enumerate(loop):\n",
    "#         print(\"asdasd\")\n",
    "        x = image.to(device)\n",
    "        y = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        \n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if( j % 10 == 0):\n",
    "            print(loss)\n",
    "#             loss_arr.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cbf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91e964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32c5d7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31777</th>\n",
       "      <td>31777</td>\n",
       "      <td>61</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11365</th>\n",
       "      <td>11365</td>\n",
       "      <td>38</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36847</th>\n",
       "      <td>36847</td>\n",
       "      <td>64</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28481</th>\n",
       "      <td>28481</td>\n",
       "      <td>61</td>\n",
       "      <td>980</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>8021</td>\n",
       "      <td>68</td>\n",
       "      <td>829</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35928</th>\n",
       "      <td>35928</td>\n",
       "      <td>71</td>\n",
       "      <td>130</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30577</th>\n",
       "      <td>30577</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26310</th>\n",
       "      <td>26310</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22393</th>\n",
       "      <td>22393</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38006</th>\n",
       "      <td>38006</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name category  height  width\n",
       "31777      31777       61    1080   1080\n",
       "11365      11365       38    1080   1920\n",
       "36847      36847       64    1080   1080\n",
       "28481      28481       61     980    736\n",
       "8021        8021       68     829    550\n",
       "...          ...      ...     ...    ...\n",
       "35928      35928       71     130    197\n",
       "30577      30577       46       0      0\n",
       "26310      26310       46       0      0\n",
       "22393      22393       57       0      0\n",
       "38006      38006       53       0      0\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.meta.sort_values('height',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18606e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11365</th>\n",
       "      <td>11365</td>\n",
       "      <td>38</td>\n",
       "      <td>1080</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18036</th>\n",
       "      <td>18036</td>\n",
       "      <td>52</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32657</th>\n",
       "      <td>32657</td>\n",
       "      <td>59</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38353</th>\n",
       "      <td>38353</td>\n",
       "      <td>61</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38198</th>\n",
       "      <td>38198</td>\n",
       "      <td>40</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35831</th>\n",
       "      <td>35831</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26310</th>\n",
       "      <td>26310</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38006</th>\n",
       "      <td>38006</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30577</th>\n",
       "      <td>30577</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22393</th>\n",
       "      <td>22393</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name category  height  width\n",
       "11365      11365       38    1080   1920\n",
       "18036      18036       52     720   1280\n",
       "32657      32657       59     720   1280\n",
       "38353      38353       61     720   1280\n",
       "38198      38198       40     720   1280\n",
       "...          ...      ...     ...    ...\n",
       "35831      35831       46     130    130\n",
       "26310      26310       46       0      0\n",
       "38006      38006       53       0      0\n",
       "30577      30577       46       0      0\n",
       "22393      22393       57       0      0\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.meta.sort_values('width',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bfa529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42367a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4cf238b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 400, 600])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24194390",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 248 241]\n",
      "  [255 248 241]\n",
      "  [255 248 241]\n",
      "  ...\n",
      "  [254 245 232]\n",
      "  [254 245 232]\n",
      "  [254 245 232]]\n",
      "\n",
      " [[255 248 241]\n",
      "  [255 248 241]\n",
      "  [255 248 241]\n",
      "  ...\n",
      "  [254 245 232]\n",
      "  [254 245 232]\n",
      "  [254 245 232]]\n",
      "\n",
      " [[255 248 241]\n",
      "  [255 248 241]\n",
      "  [255 248 241]\n",
      "  ...\n",
      "  [254 245 232]\n",
      "  [254 245 232]\n",
      "  [254 245 232]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[219 213 202]\n",
      "  [219 213 202]\n",
      "  [218 212 201]\n",
      "  ...\n",
      "  [184 180 161]\n",
      "  [185 181 163]\n",
      "  [185 181 162]]\n",
      "\n",
      " [[219 213 202]\n",
      "  [219 213 202]\n",
      "  [218 212 201]\n",
      "  ...\n",
      "  [182 179 158]\n",
      "  [183 179 160]\n",
      "  [183 180 159]]\n",
      "\n",
      " [[219 213 202]\n",
      "  [219 213 202]\n",
      "  [218 212 201]\n",
      "  ...\n",
      "  [181 178 157]\n",
      "  [182 179 158]\n",
      "  [182 179 158]]]\n",
      "./train_data\\1.jpg\n"
     ]
    }
   ],
   "source": [
    "# to_image = transforms.ToPILImage()\n",
    "\n",
    "# test = to_image(train_data[1][0])\n",
    "# test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "978df5b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'43'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets.meta.loc[1,'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "436060d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94305668",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_datasets\u001b[49m\u001b[38;5;241m.\u001b[39mmeta[test_datasets\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "test_datasets.meta[test_datasets.meta['category']==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9873e4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e66229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39c29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9894388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16b92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fa24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec641b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df7129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae30d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8955270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "def train() :\n",
    "    #TODO: Make your own training code\n",
    "\n",
    "    # You SHOULD save your model by\n",
    "    # torch.save(model.state_dict(), './checkpoint.pth') \n",
    "    # You SHOULD not modify the save path\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_model(model_name, checkpoint_path):\n",
    "    \n",
    "    model = model_name()\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def test():\n",
    "    \n",
    "    model_name = MyModel\n",
    "    checkpoint_path = './model.pth' \n",
    "    mode = 'test' \n",
    "    data_dir = \"./test_data\"\n",
    "    meta_path = \"./answer.json\"\n",
    "    model = get_model(model_name,checkpoint_path)\n",
    "\n",
    "    data_transforms = {\n",
    "        'train' :\"YOUR_DATA_TRANSFORM_FUNCTION\" , \n",
    "        'test': \"YOUR_DATA_TRANSFORM_FUNCTION\"\n",
    "    }\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    test_datasets = MyDataset(meta_path, data_dir, data_transforms['mode'])\n",
    "\n",
    "    batch_size = 1\n",
    "    # Create training and validation dataloaders\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Detect if we have a GPU available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Send the model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Set model as evaluation mode\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.eval()\n",
    "    \n",
    "    # Inference\n",
    "    result = []\n",
    "    for images, filename in tqdm(test_dataloader):\n",
    "        num_image = images.shape[0]\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for i in range(num_image):\n",
    "            result.append({\n",
    "                'filename': filename[i],\n",
    "                'class': preds[i].item()\n",
    "            })\n",
    "\n",
    "    result = sorted(result,key=lambda x : int(x['filename'].split('.')[0]))\n",
    "    \n",
    "    # Save to csv\n",
    "    with open('./result.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['filename','class'])\n",
    "        for res in result:\n",
    "            writer.writerow([res['filename'], result['class']])\n",
    "\n",
    "\n",
    "def main() :\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09878c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
