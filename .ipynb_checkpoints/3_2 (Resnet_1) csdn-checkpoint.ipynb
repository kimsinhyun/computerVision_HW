{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69a4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from turtle import forward\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary   import summary\n",
    "from torchmetrics import F1Score\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image \n",
    "import visdom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9519822",
   "metadata": {},
   "source": [
    "# 1. define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2254bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_number(col):\n",
    "    return int(col.split(\".\")[0])\n",
    "\n",
    "class MyDataset(Dataset) :\n",
    "\n",
    "    def __init__(self,meta_path,root_dir,transform=None,pre_transform=None) :\n",
    "        super().__init__()\n",
    "        #===============meta data===============\n",
    "        with open(meta_path, 'r') as file:\n",
    "            temp_meta_data = json.load(file)\n",
    "        meta = pd.json_normalize(temp_meta_data['annotations'])\n",
    "        meta['file_name'] = meta['file_name'].apply(parse_file_number)\n",
    "        meta = meta.sort_values(\"file_name\").reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        meta['file_name'] = meta['file_name'].map(lambda x :  self.root_dir + '/' + str(x) +'.jpg')\n",
    "        self.X = []\n",
    "        loop = tqdm(list(meta['file_name']), total=len(meta['file_name']), leave=True)\n",
    "\n",
    "        for i, X in enumerate(loop):\n",
    "#             print(i)\n",
    "            try:\n",
    "                self.X.append(pre_transform(Image.open(X).convert(\"RGB\")))\n",
    "            except:\n",
    "                pass\n",
    "        self.y = meta['category']\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self,idx) :\n",
    "#         X, y = self.transforms(self.X[idx]), self.y[idx]\n",
    "        X, y = self.transform(self.X[idx]), int(self.y[idx])\n",
    "        return X, torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eedde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40000/40000 [02:29<00:00, 268.13it/s]\n"
     ]
    }
   ],
   "source": [
    "batch = 25\n",
    "\n",
    "mode = 'train' \n",
    "train_data_dir = \"./train_data\"\n",
    "meta_path = \"./answer.json\"\n",
    "\n",
    "# Create training and validation datasets\n",
    "# test_datasets = MyDataset(meta_path, data_dir, data_transforms['train'])\n",
    "\n",
    "pre_transformer = transforms.Compose([\n",
    "    transforms.Resize((400,400)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "])\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "# train_data = MyDataset(meta_path, train_data_dir, transform=transformer)\n",
    "train_data = MyDataset(meta_path, train_data_dir, transform=transformer,pre_transform=pre_transformer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d28a5f",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9d7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 分类数目\n",
    "num_class = 80\n",
    "# 各层数目\n",
    "resnet18_params = [2, 2, 2, 2]\n",
    "resnet34_params = [3, 4, 6, 3]\n",
    "resnet50_params = [3, 4, 6, 3]\n",
    "resnet101_params = [3, 4, 23, 3]\n",
    "resnet152_params = [3, 8, 36, 3]\n",
    "\n",
    "\n",
    "# 定义Conv1层\n",
    "def Conv1(in_planes, places, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_planes,out_channels=places,kernel_size=7,stride=stride,padding=3, bias=False),\n",
    "        nn.BatchNorm2d(places),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "\n",
    "\n",
    "# 浅层的残差结构\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,in_places,places, stride=1,downsampling=False, expansion = 1):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "        # torch.Size([1, 64, 56, 56]), stride = 1\n",
    "        # torch.Size([1, 128, 28, 28]), stride = 2\n",
    "        # torch.Size([1, 256, 14, 14]), stride = 2\n",
    "        # torch.Size([1, 512, 7, 7]), stride = 2\n",
    "        self.basicblock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_places, out_channels=places, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=places, out_channels=places, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(places * self.expansion),\n",
    "        )\n",
    "\n",
    "        # torch.Size([1, 64, 56, 56])\n",
    "        # torch.Size([1, 128, 28, 28])\n",
    "        # torch.Size([1, 256, 14, 14])\n",
    "        # torch.Size([1, 512, 7, 7])\n",
    "        # 每个大模块的第一个残差结构需要改变步长\n",
    "        if self.downsampling:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_places, out_channels=places*self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(places*self.expansion)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 实线分支\n",
    "        residual = x\n",
    "        out = self.basicblock(x)\n",
    "\n",
    "        # 虚线分支\n",
    "        if self.downsampling:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 深层的残差结构\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    # 注意:默认 downsampling=False\n",
    "    def __init__(self,in_places,places, stride=1,downsampling=False, expansion = 4):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            # torch.Size([1, 64, 56, 56])，stride=1\n",
    "            # torch.Size([1, 128, 56, 56])，stride=1\n",
    "            # torch.Size([1, 256, 28, 28]), stride=1\n",
    "            # torch.Size([1, 512, 14, 14]), stride=1\n",
    "            nn.Conv2d(in_channels=in_places,out_channels=places,kernel_size=1,stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # torch.Size([1, 64, 56, 56])，stride=1\n",
    "            # torch.Size([1, 128, 28, 28]), stride=2\n",
    "            # torch.Size([1, 256, 14, 14]), stride=2\n",
    "            # torch.Size([1, 512, 7, 7]), stride=2\n",
    "            nn.Conv2d(in_channels=places, out_channels=places, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # torch.Size([1, 256, 56, 56])，stride=1\n",
    "            # torch.Size([1, 512, 28, 28]), stride=1\n",
    "            # torch.Size([1, 1024, 14, 14]), stride=1\n",
    "            # torch.Size([1, 2048, 7, 7]), stride=1\n",
    "            nn.Conv2d(in_channels=places, out_channels=places * self.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places * self.expansion),\n",
    "        )\n",
    "\n",
    "        # torch.Size([1, 256, 56, 56])\n",
    "        # torch.Size([1, 512, 28, 28])\n",
    "        # torch.Size([1, 1024, 14, 14])\n",
    "        # torch.Size([1, 2048, 7, 7])\n",
    "        if self.downsampling:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_places, out_channels=places*self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(places*self.expansion)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 实线分支\n",
    "        residual = x\n",
    "        out = self.bottleneck(x)\n",
    "\n",
    "        # 虚线分支\n",
    "        if self.downsampling:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,blocks, blockkinds, num_classes=num_class):\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        self.blockkinds = blockkinds\n",
    "        self.conv1 = Conv1(in_planes = 3, places= 64)\n",
    "\n",
    "        # 对应浅层网络结构\n",
    "        if self.blockkinds == BasicBlock:\n",
    "            self.expansion = 1\n",
    "            # 64 -> 64\n",
    "            self.layer1 = self.make_layer(in_places=64, places=64, block=blocks[0], stride=1)\n",
    "            # 64 -> 128\n",
    "            self.layer2 = self.make_layer(in_places=64, places=128, block=blocks[1], stride=2)\n",
    "            # 128 -> 256\n",
    "            self.layer3 = self.make_layer(in_places=128, places=256, block=blocks[2], stride=2)\n",
    "            # 256 -> 512\n",
    "            self.layer4 = self.make_layer(in_places=256, places=512, block=blocks[3], stride=2)\n",
    "\n",
    "            self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # 对应深层网络结构\n",
    "        if self.blockkinds == Bottleneck:\n",
    "            self.expansion = 4\n",
    "            # 64 -> 64\n",
    "            self.layer1 = self.make_layer(in_places = 64, places= 64, block=blocks[0], stride=1)\n",
    "            # 256 -> 128\n",
    "            self.layer2 = self.make_layer(in_places = 256,places=128, block=blocks[1], stride=2)\n",
    "            # 512 -> 256\n",
    "            self.layer3 = self.make_layer(in_places=512,places=256, block=blocks[2], stride=2)\n",
    "            # 1024 -> 512\n",
    "            self.layer4 = self.make_layer(in_places=1024,places=512, block=blocks[3], stride=2)\n",
    "\n",
    "            self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "\n",
    "        # 初始化网络结构\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # 采用了何凯明的初始化方法\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def make_layer(self, in_places, places, block, stride):\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # torch.Size([1, 64, 56, 56])  -> torch.Size([1, 256, 56, 56])， stride=1 故w，h不变\n",
    "        # torch.Size([1, 256, 56, 56]) -> torch.Size([1, 512, 28, 28])， stride=2 故w，h变\n",
    "        # torch.Size([1, 512, 28, 28]) -> torch.Size([1, 1024, 14, 14])，stride=2 故w，h变\n",
    "        # torch.Size([1, 1024, 14, 14]) -> torch.Size([1, 2048, 7, 7])， stride=2 故w，h变\n",
    "        # 此步需要通过虚线分支，downsampling=True\n",
    "        layers.append(self.blockkinds(in_places, places, stride, downsampling =True))\n",
    "\n",
    "        # torch.Size([1, 256, 56, 56]) -> torch.Size([1, 256, 56, 56])\n",
    "        # torch.Size([1, 512, 28, 28]) -> torch.Size([1, 512, 28, 28])\n",
    "        # torch.Size([1, 1024, 14, 14]) -> torch.Size([1, 1024, 14, 14])\n",
    "        # torch.Size([1, 2048, 7, 7]) -> torch.Size([1, 2048, 7, 7])\n",
    "        # print(\"places*self.expansion:\", places*self.expansion)\n",
    "        # print(\"block:\", block)\n",
    "        # 此步需要通过实线分支，downsampling=False， 每个大模块的第一个残差结构需要改变步长\n",
    "        for i in range(1, block):\n",
    "            layers.append(self.blockkinds(places*self.expansion, places))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # conv1层\n",
    "        x = self.conv1(x)   # torch.Size([1, 64, 56, 56])\n",
    "\n",
    "        # conv2_x层\n",
    "        x = self.layer1(x)  # torch.Size([1, 256, 56, 56])\n",
    "        # conv3_x层\n",
    "        x = self.layer2(x)  # torch.Size([1, 512, 28, 28])\n",
    "        # conv4_x层\n",
    "        x = self.layer3(x)  # torch.Size([1, 1024, 14, 14])\n",
    "        # conv5_x层\n",
    "        x = self.layer4(x)  # torch.Size([1, 2048, 7, 7])\n",
    "\n",
    "        x = self.avgpool(x) # torch.Size([1, 2048, 1, 1]) / torch.Size([1, 512])\n",
    "        x = x.view(x.size(0), -1)   # torch.Size([1, 2048]) / torch.Size([1, 512])\n",
    "        x = self.fc(x)      # torch.Size([1, 5])\n",
    "\n",
    "        return x\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(resnet18_params, BasicBlock)\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(resnet34_params, BasicBlock)\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(resnet50_params, Bottleneck)\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(resnet101_params, Bottleneck)\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(resnet152_params, Bottleneck)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ResNet101().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247d887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ea84e83",
   "metadata": {},
   "source": [
    "# 트레커 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c79fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")\n",
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=loss_value,\n",
    "             win = loss_plot,\n",
    "             update='append'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bada24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.005,momentum=0.9)\n",
    "\n",
    "lr_sche = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91ebae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                               | 20/1600 [00:11<14:55,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 4.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                              | 40/1600 [00:23<14:44,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    40] loss: 4.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                             | 60/1600 [00:34<14:29,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    60] loss: 4.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                            | 80/1600 [00:45<14:15,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    80] loss: 4.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                          | 100/1600 [00:57<14:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▉                                                                         | 120/1600 [01:08<13:54,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   120] loss: 4.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▉                                                                        | 140/1600 [01:19<13:42,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   140] loss: 4.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 160/1600 [01:30<13:32,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   160] loss: 4.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▉                                                                      | 180/1600 [01:42<13:20,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   180] loss: 4.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                     | 200/1600 [01:53<13:08,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 4.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▊                                                                    | 220/1600 [02:04<12:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   220] loss: 4.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▊                                                                   | 240/1600 [02:15<12:46,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   240] loss: 4.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▊                                                                  | 260/1600 [02:27<14:03,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   260] loss: 4.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▊                                                                 | 280/1600 [02:39<13:47,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   280] loss: 4.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▊                                                                | 300/1600 [02:50<12:13,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 4.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▊                                                               | 320/1600 [03:02<12:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   320] loss: 4.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▊                                                              | 340/1600 [03:13<12:13,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   340] loss: 4.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▏                                                             | 347/1600 [03:18<11:56,  1.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m lr_sche\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m19\u001b[39m:    \u001b[38;5;66;03m# print every 30 mini-batches\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     loss_tracker(loss_plt, torch\u001b[38;5;241m.\u001b[39mTensor([running_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m20\u001b[39m]), torch\u001b[38;5;241m.\u001b[39mTensor([i \u001b[38;5;241m+\u001b[39m epoch\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader) ]))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(len(trainloader))\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    lr_sche.step()\n",
    "    loop = tqdm(train_loader, total=len(train_loader), leave=True)\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "    for i, (inputs, labels) in enumerate(loop):\n",
    "        # get the inputs\n",
    "#         print(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_sche.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 30 mini-batches\n",
    "            loss_tracker(loss_plt, torch.Tensor([running_loss/20]), torch.Tensor([i + epoch*len(train_loader) ]))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "    torch.save(net.state_dict(), \"./model_\"+ str(epoch) + \".pth\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db882d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
